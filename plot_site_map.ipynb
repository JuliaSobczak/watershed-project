{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b5f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import directories\n",
    "import os\n",
    "import pathlib\n",
    "import zipfile\n",
    "\n",
    "import contextily as cx\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84687e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "working_dir = os.path.join(\n",
    "    pathlib.Path.home(), 'earth-analytics', 'data', 'watershed-project')\n",
    "if not os.path.exists(working_dir):\n",
    "    print('{} does not exist. Creating...'.format(working_dir))\n",
    "    os.makedirs(working_dir)\n",
    "\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583a26c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Download and import the site coordinates for plotting (saved on github)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sites_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/lechipman/watershed-project/master/UAV_gps_coords.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m download \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(sites_url)\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Reading the downloaded content and turning it into a pandas dataframe\u001b[39;00m\n\u001b[0;32m      6\u001b[0m sites_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(io\u001b[38;5;241m.\u001b[39mStringIO(download\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# Download and import the site coordinates for plotting (saved on github)\n",
    "sites_url = 'https://raw.githubusercontent.com/lechipman/watershed-project/master/UAV_gps_coords.csv'\n",
    "download = requests.get(sites_url).content\n",
    "\n",
    "# Reading the downloaded content and turning it into a pandas dataframe\n",
    "sites_df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "\n",
    "# Select one location from each site to map\n",
    "sites_short_df = sites_df.iloc[[0, 7, 17, 29, -1]]\n",
    "sites_short_df\n",
    "\n",
    "# # Create gdf of study sites\n",
    "# sites_gdf = gpd.GeoDataFrame(\n",
    "#     sites_short_df,\n",
    "#     geometry=gpd.points_from_xy(sites_short_df['lon'],\n",
    "#                                 sites_short_df['lat']),\n",
    "#     crs='EPSG:4326')\n",
    "# sites_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f5e9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and cache watershed boundary dataset\n",
    "override_cache = False\n",
    "wbd_10_url = (\n",
    "    \"https://prd-tnm.s3.amazonaws.com/StagedProducts/\"\n",
    "    \"Hydrography/WBD/HU2/Shape/WBD_10_HU2_Shape.zip\")\n",
    "\n",
    "wbd_10_dir = 'water-boundary-dataset-hu10'\n",
    "wbd_10_path = os.path.join(wbd_10_dir, wbd_10_dir + '.zip')\n",
    "\n",
    "# Cache WBD file\n",
    "if not os.path.exists(wbd_10_dir):\n",
    "    os.makedirs(wbd_10_dir)\n",
    "\n",
    "    if (not os.path.exists(wbd_10_path)) or override_cache:\n",
    "        # Download full WBD 10 as zipfile\n",
    "        response = requests.get(wbd_10_url)\n",
    "\n",
    "        # Write in respose content using context manager\n",
    "        with open(wbd_10_path, 'wb') as wbd_10_file:\n",
    "            wbd_10_file.write(response.content)\n",
    "\n",
    "        # Decompress zip file\n",
    "        with zipfile.ZipFile(wbd_10_path, 'r')as wbd_zipfile:\n",
    "            wbd_zipfile.extractall(wbd_10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a2234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select study area, St Vrain watershed, and save gdf\n",
    "wbd_10_path = os.path.join(wbd_10_dir, 'Shape', 'WBDHU8.shp')\n",
    "wbd_10_gdf = gpd.read_file(wbd_10_path)\n",
    "vrain_gdf = wbd_10_gdf[wbd_10_gdf.name.str.contains('Vrain')]\n",
    "\n",
    "# Set CRS to same as site points\n",
    "vrain_crs_gdf = vrain_gdf.to_crs(crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39023a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Boulder County streams data and create gdf\n",
    "# Source = University of Colorado, Boulder, GeoLibrary,\n",
    "# https://geo.colorado.edu/catalog/47540-5ca23860d43267000b8c744e\n",
    "stream_url = \"https://geo.colorado.edu/apps/geolibrary/datasets/STREAMSx4.zip\"\n",
    "stream_dir = 'co_streams'\n",
    "stream_path = os.path.join(stream_dir, stream_dir + '.zip')\n",
    "\n",
    "override_cache = True\n",
    "if not os.path.exists(stream_dir):\n",
    "    os.makedirs(stream_dir)\n",
    "\n",
    "    if not os.path.exists(stream_path) or override_cache:\n",
    "        print('{} does not exist. Downloading...'.format(stream_path))\n",
    "\n",
    "        # Open stream file\n",
    "        response = requests.get(stream_url)\n",
    "\n",
    "        # Open a local file with wb permission and write response content\n",
    "        with open(stream_path, 'wb') as stream_file:\n",
    "            stream_file.write(response.content)\n",
    "\n",
    "        # Decompress zip file\n",
    "        with zipfile.ZipFile(stream_path, 'r') as stream_zipfile:\n",
    "            stream_zipfile.extractall(stream_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574f9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\miniconda3\\envs\\earth-analytics-python\\lib\\site-packages\\geopandas\\tools\\clip.py:66: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  clipped.loc[\n"
     ]
    }
   ],
   "source": [
    "stream_gdf = gpd.read_file(stream_path)\n",
    "\n",
    "# Set CRS to same as site points\n",
    "stream_crs_gdf = stream_gdf.to_crs(crs='EPSG:4326')\n",
    "\n",
    "# Clip stream data to st vrain watershed boundary\n",
    "stream_clipped_gdf = stream_crs_gdf.clip(vrain_crs_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03550224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Watershed and Streams\n",
    "def plot_study_sites():\n",
    "    \"\"\"Creates a map of study sites in the St. Vrain Watershed\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 16))\n",
    "    ax.set_title(\"Site Locations in the St. Vrain Watershed\",\n",
    "                 pad=20,\n",
    "                 fontsize=16)\n",
    "\n",
    "    stream_clipped_gdf.plot(ax=ax, color='blue')\n",
    "    vrain_crs_gdf.plot(ax=ax, facecolor='cyan', alpha=0.5)\n",
    "\n",
    "    site_symbol_dict = {\n",
    "        'AV GCP1': '*',\n",
    "        'HW93 GCP1': '*',\n",
    "        'LEG1-GCP1': '*',\n",
    "        'VV GCP1': '*',\n",
    "        'HM': '*'\n",
    "    }\n",
    "\n",
    "    site_name_dict = {\n",
    "        'AV GCP1': 'Apple Valley North',\n",
    "        'HW93 GCP1': 'Highway 93',\n",
    "        'LEG1-GCP1': 'Legacy 1',\n",
    "        'VV GCP1': 'Van Vleet',\n",
    "        'HM': 'Hall Meadows'\n",
    "    }\n",
    "\n",
    "    for i, gdf in sites_gdf.groupby('name'):\n",
    "        gdf.plot(ax=ax,\n",
    "                 marker=site_symbol_dict[i],\n",
    "                 label=site_name_dict[i],\n",
    "                 markersize=150,\n",
    "                 legend=True,\n",
    "                 zorder=3)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_axis_off()\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0)\n",
    "    #sites_gdf.plot(ax=ax, color='black', marker = 'x', markersize=40)\n",
    "\n",
    "    cx.add_basemap(ax, crs=vrain_crs_gdf.crs, zoom=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
